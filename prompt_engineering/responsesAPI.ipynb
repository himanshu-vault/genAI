{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cf60ac",
   "metadata": {},
   "source": [
    "#### Speaking via reasoning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2de985ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, semicolons are optional in JavaScript thanks to automatic semicolon insertion (ASI). However, relying on ASI can lead to unexpected behaviors. To maintain clarity and avoid errors, it’s often recommended to use semicolons consistently, like the steady breath in our practice. Keep your code flowing smoothly!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    # reasoning={\"effort\": \"low\"},\n",
    "    instructions=\"Talk like a yoga trainer!\",\n",
    "    input=\"Are semicolons optional in JavaScript? Explain in no more than 50 words.\",\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333b2148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0101301c4b22d023006916fe91db108195b4580f3bc1715f55', created_at=1763114641.0, error=None, incomplete_details=None, instructions='Talk like a pirate.', metadata={}, model='gpt-5-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0101301c4b22d023006916fe92b07481958cc77ee1d1078e6d', summary=[], type='reasoning', encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0101301c4b22d023006916fea7f1dc819580d1f5a89cc1ccf9', content=[ResponseOutputText(annotations=[], text='Aye, mostly optional, thanks t’ Automatic Semicolon Insertion (ASI). But mind ye, thar be reefs.\\n\\nWhen ye must use ’em:\\n- do...while needs a trailing semicolon.\\n- for (init; test; update) needs the two semicolons inside the head.\\n\\nWhen leavin’ ’em out can scuttle yer ship:\\n- return, break, continue, throw: the value must be on the same line. A newline makes ASI drop a semicolon early.\\n- A new line startin’ with one o’ these can glom onto the previous line: ( [ ` + - ++ -- / . \\n  - Examples: \\n    - x = y\\n      +z becomes x = y + z\\n    - foo\\n      (bar) becomes foo(bar) instead o’ a new call\\n    - name\\n      `templ` becomes a tagged template (name`templ`)\\n    - Previous token + /pattern/ can be read as division, not a regex\\n\\nPractical charts fer smooth sailin’:\\n- Either always use semicolons, or\\n- Go “no-semi” but begin any line that starts with ( or [ or ` or + or - or / or . with a defensive leading semicolon.\\n- Keep values on the same line as return/break/continue/throw.\\n- Let tools mind the rigging: Prettier can run no-semi safely; ESLint’s “semi” rule can enforce yer choice.\\n\\nSo aye, ye can skip ’em—if ye know the currents. Otherwise, drop the little flags and sail safe.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort='low', generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=24, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=978, output_tokens_details=OutputTokensDetails(reasoning_tokens=640), total_tokens=1002), user=None, billing={'payer': 'openai'}, prompt_cache_key=None, prompt_cache_retention=None, safety_identifier=None, store=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0718f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseUsage(input_tokens=36, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=63, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=99)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.background\n",
    "response.created_at\n",
    "response.error\n",
    "response.id\n",
    "response.instructions\n",
    "response.model\n",
    "response.max_output_tokens\n",
    "response.output\n",
    "response.output_text\n",
    "response.parallel_tool_calls\n",
    "response.service_tier\n",
    "response.usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf3be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_setattr_handlers__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " '_request_id',\n",
       " '_setattr_handler',\n",
       " 'background',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'created_at',\n",
       " 'dict',\n",
       " 'error',\n",
       " 'from_orm',\n",
       " 'id',\n",
       " 'incomplete_details',\n",
       " 'instructions',\n",
       " 'json',\n",
       " 'max_output_tokens',\n",
       " 'max_tool_calls',\n",
       " 'metadata',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'object',\n",
       " 'output',\n",
       " 'output_text',\n",
       " 'parallel_tool_calls',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'previous_response_id',\n",
       " 'prompt',\n",
       " 'reasoning',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'service_tier',\n",
       " 'status',\n",
       " 'temperature',\n",
       " 'text',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'tool_choice',\n",
       " 'tools',\n",
       " 'top_logprobs',\n",
       " 'top_p',\n",
       " 'truncation',\n",
       " 'update_forward_refs',\n",
       " 'usage',\n",
       " 'user',\n",
       " 'validate']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in dir(response):\n",
    "    eval('response.{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82b428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e912e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
